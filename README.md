## Models used
['aya','mistral','llama3','phi3','gpt-4o','gpt-4-turbo','gpt-3.5-turbo-0125'] - all but the GPT are used as local models via Ollama API, GPT is used via Ollama API as well 

## Jupyter Notebooks
[lesson1.ipynb](https://github.com/alexb7373/ai_course/blob/master/lesson1.ipynb)

[lesson2.ipynb](https://github.com/alexb7373/ai_course/blob/master/lesson2.ipynb)

## Results
results are depicted in the 

[answers_lesson01.json](https://github.com/alexb7373/ai_course/blob/master/answers_lesson01.json) file, and in [ANSWERS_LESSON01.md](https://github.com/alexb7373/ai_course/blob/master/ANSWERS_LESSON01.md)

[answers_lesson02.json](https://github.com/alexb7373/ai_course/blob/master/answers_lesson02.json) file, and in [ANSWERS_LESSON02.md](https://github.com/alexb7373/ai_course/blob/master/ANSWERS_LESSON02.md)

Worth noting:
* 'aya' is a surprisingly mature model - producing good results
* 'gpt-4o' is 'the king' anyway IMHO, evolution is seen over 'gpt-4' and 'gpt-3.5'. Output is pleasantly produced with markdown syntax.
* 'mistral','phi3' created the story for children - in English, instead of Czech
* 'llama3' - responded in English only (did understand the prompt in Czech though)
