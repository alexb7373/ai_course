## Models used
['aya','mistral','llama3','phi3','gpt-4o','gpt-4-turbo','gpt-3.5-turbo-0125'] - all but the GPT are used as local models via Ollama API, GPT is used via Ollama API as well 

## Jupyter Notebook
[ollama_tests.ipynb](https://github.com/alexb7373/ai_course/blob/master/ollama_tests.ipynb)

## Results
results are depicted in the [answers_lesson01.json](https://github.com/alexb7373/ai_course/blob/master/answers_lesson01.json) file, and in [ANSWERS_LESSON01.md](https://github.com/alexb7373/ai_course/blob/master/ANSWERS_LESSON01.md)

Worth noting:
* 'aya' is a surprisingly mature model - producing good results
* 'gpt-4o' is 'the king' anyway IMHO
* 'mistral','phi3' created the story for children - in English, instead of Czech
* 'llama3' - responded in English only (did understand the prompt in Czech though)
