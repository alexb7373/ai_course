{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b05bc8f-8f25-4400-ace0-0512d3a7b696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.llms import Ollama\n",
    "import json, re, os\n",
    "from langchain_chroma import Chroma\n",
    "from docx import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4cc6f3-0666-4519-993e-e41d6bfcd3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import AIMessage, HumanMessage, get_buffer_string\n",
    "from langchain_core.prompts import format_document\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "from operator import itemgetter\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_openai import OpenAI, ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "from langchain.callbacks.tracers import ConsoleCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c3c6a0-2902-440b-922c-0173b95ef81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46ec1c6-43e4-482c-892a-5816402afe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876bfe16-66ca-436a-b85c-5519175fe3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_markdown(md_text):\n",
    "    display(Markdown(md_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bf8370-c57b-4cfb-975a-0df0ddb72f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv(find_dotenv())  # read local .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6c8a5b-b393-41ff-89b9-1060694c2ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://levelup.gitconnected.com/introduction-to-ollama-part-1-1156f9563b8d\n",
    "# https://levelup.gitconnected.com/introduction-to-ollama-part-2-e8516105f600\n",
    "# https://ollama.com/library\n",
    "# https://stackoverflow.com/questions/77550506/what-is-the-right-way-to-do-system-prompting-with-ollama-in-langchain-using-pyth\n",
    "# https://python.langchain.com/v0.2/docs/integrations/chat/openai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029db777-9d86-4d47-8736-0802a215333e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ollama list\n",
    "# NAME            ID              SIZE    MODIFIED\n",
    "# aya:latest      7ef8c4942023    4.8 GB  3 hours ago\n",
    "# phi3:latest     64c1188f2485    2.4 GB  3 hours ago\n",
    "# llama3:latest   365c0bd3c000    4.7 GB  3 hours ago\n",
    "# mistral:latest  2ae6f6dd7a3d    4.1 GB  4 hours ago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19dfaf0-646e-484a-a640-87c91ddb9684",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_path = '/mnt/c/Users/alexb/OneDrive/Energy Regulation/process/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f104e17d-64e3-4c7c-afe3-bddfa91487fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_docx(file_path_):\n",
    "    doc = Document(file_path_)\n",
    "    full_text = []\n",
    "    for para in doc.paragraphs:\n",
    "        full_text.append(para.text)\n",
    "    return '\\n'.join(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313b8f81-b60d-4bff-89cf-b1cb573a95a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6adc1f-9dfb-46ba-8c59-1f49875ee158",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirpath, dirnames, filenames in os.walk(docs_path):\n",
    "    for fidx, file in enumerate(filenames):\n",
    "            # print(file)\n",
    "        if file.endswith(\".docx\"):\n",
    "            file_path = os.path.join(dirpath, file)\n",
    "            try:\n",
    "                text_from_doc = read_docx(file_path)\n",
    "                with open(file_path+f'_{fidx:02d}'+'.txt', 'wt+') as f:\n",
    "                    f.write(text_from_doc)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6331582-02c6-4837-b1b7-02fda6eba975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_path = '/home/alexb/projects/AI-developer/7_RAG-2/2_vector_db/1_chromadb/source'\n",
    "source_path = docs_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfe4e8d-1e99-4a6b-8d07-dff079154ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirpath, dirnames, filenames in os.walk(source_path):\n",
    "    for file in filenames:\n",
    "        # print(file)\n",
    "        if file.endswith(\".txt\"):\n",
    "            try:\n",
    "                loader = TextLoader(os.path.join(source_path, file), encoding=\"utf-8\")\n",
    "                docs.extend(loader.load_and_split())\n",
    "            except Exception as e:\n",
    "                # print(e)\n",
    "                pass\n",
    "\n",
    "# print(f\"{len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0035f4b-7d5f-4af6-a64d-71fc77a8253a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96983123-d569-41a7-9e75-a1e23eb2d9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding function\n",
    "# embeddings = OllamaEmbeddings(model=\"mistral\")\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54889de-dde1-4f02-9033-4432b1c3ac40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing to the db\n",
    "db = Chroma.from_documents(texts, embeddings, persist_directory=\"./chroma_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87af55b2-7857-4a56-a74c-ce3aa144e38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting DB for use\n",
    "db = Chroma(persist_directory=\"./chroma_db\", embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0814c7aa-ba9c-40fd-abb4-666d681cf06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d878fa-5473-429f-81bc-5075c043fc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "# llm = Ollama(model=\"mistral\") # returns TEXT\n",
    "# llm = Ollama(model=\"mistral:instruct\") # returns TEXT\n",
    "# llm = ChatOllama(model=\"mistral:v0.2\") # returns MESSAGE object\n",
    "# llm = ChatOllama(model=\"mistral:instruct\") # returns MESSAGE object\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27162d52-b929-48ea-a608-9bafcd4cd358",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../openai_api_key.txt') as f:\n",
    "    openai_api_key = f.read().strip('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f5c64e-0d2c-43a2-a393-9b8de6124f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cff327-e0d7-4a91-b79b-7a17d5b5a085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _combine_documents(docs, document_separator=\"\\n\\n\"):\n",
    "    document_prompt = PromptTemplate.from_template(template=\"{page_content}\")\n",
    "    doc_strings = [format_document(doc, document_prompt) for doc in docs]\n",
    "    return document_separator.join(doc_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5586d3-68ec-438b-98b5-757489fddf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_context = {\n",
    "    \"chat_history\": itemgetter(\"chat_history\"),\n",
    "    \"context\": itemgetter(\"question\") | retriever | _combine_documents,\n",
    "    \"question\": lambda x: x[\"question\"],\n",
    "}\n",
    "\n",
    "# FULL Chain ----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1375a31f-c361-4f4f-b981-4497a160c3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question from the user, consider the Chat history and provided context. Use your knowledge as well.\n",
    "\n",
    "Chat History:\n",
    "===\n",
    "{chat_history}\n",
    "===\n",
    "\n",
    "Context:\n",
    "===\n",
    "{context}\n",
    "===\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "ANSWER_PROMPT = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24fa0af-6f72-4828-b825-12ce5db2da62",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversational_qa_chain = _context | ANSWER_PROMPT | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d48d7d-c09b-47db-bb9d-49c353dc6ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------\n",
    "# Invoke 1\n",
    "question = \"What are the primary stakeholders mentioned in the context provided?\"\n",
    "chat_history = []\n",
    "result = conversational_qa_chain.invoke(\n",
    "    {\n",
    "        \"question\": question,\n",
    "        \"chat_history\": chat_history,\n",
    "    },\n",
    "    config={\"callbacks\": [ConsoleCallbackHandler()]},\n",
    ")\n",
    "print(\"-------------------------Invoke 1-------------------------\")\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cb9756-0470-42a5-86bf-c829e0faf2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------\n",
    "chat_history.extend([HumanMessage(content=question), AIMessage(content=result.content)])\n",
    "# -----------------------------------------------------------------\n",
    "# Invoke 2\n",
    "result = conversational_qa_chain.invoke(\n",
    "    {\n",
    "        \"question\": \"What about A, B, C, D, etc.? The stakeholders that approve and/or get consulted?\",\n",
    "        # \"chat_history\": [\n",
    "        #     HumanMessage(content=\"What is the best AI Agents framework?\"),\n",
    "        #     AIMessage(content=\"Autogen.\"),\n",
    "        # ],\n",
    "        \"chat_history\": chat_history,\n",
    "    },\n",
    "    config={\"callbacks\": [ConsoleCallbackHandler()]},\n",
    ")\n",
    "print(\"-------------------------Invoke 2-------------------------\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196b7f83-b652-441f-95ad-d0a6c3b1f2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------\n",
    "chat_history.extend([HumanMessage(content=question), AIMessage(content=result.content)])\n",
    "# -----------------------------------------------------------------\n",
    "# Invoke 2\n",
    "result = conversational_qa_chain.invoke(\n",
    "    {\n",
    "        \"question\": \"Can you describe the process established in the context - for TCMs\",\n",
    "        # \"chat_history\": [\n",
    "        #     HumanMessage(content=\"What is the best AI Agents framework?\"),\n",
    "        #     AIMessage(content=\"Autogen.\"),\n",
    "        # ],\n",
    "        \"chat_history\": chat_history,\n",
    "    },\n",
    "    config={\"callbacks\": [ConsoleCallbackHandler()]},\n",
    ")\n",
    "print(\"-------------------------Invoke 2-------------------------\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d266c45b-cd3f-4977-8a66-49a6be2bf6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------\n",
    "chat_history.extend([HumanMessage(content=question), AIMessage(content=result.content)])\n",
    "# -----------------------------------------------------------------\n",
    "# Invoke 2\n",
    "result = conversational_qa_chain.invoke(\n",
    "    {\n",
    "        \"question\": \"Can you create a step-by-step process, with timelines, stakeholders and their roles, and description of steps - for each major step in the process for TCMs\",\n",
    "        # \"chat_history\": [\n",
    "        #     HumanMessage(content=\"What is the best AI Agents framework?\"),\n",
    "        #     AIMessage(content=\"Autogen.\"),\n",
    "        # ],\n",
    "        \"chat_history\": chat_history,\n",
    "    },\n",
    "    config={\"callbacks\": [ConsoleCallbackHandler()]},\n",
    ")\n",
    "print(\"-------------------------Invoke 2-------------------------\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8a0838-1651-4f7d-a8a3-c01074122523",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history[-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbc5f84-dfe0-4a48-af7e-8dbbc4c6fa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e281db-43d3-42cc-8174-a426b709bd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_markdown(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4239cb0d-7c2d-4df7-831d-9e0bc266d891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf634024-a710-46c8-a6ed-27491cdd5c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------\n",
    "chat_history.extend([HumanMessage(content=question), AIMessage(content=result.content)])\n",
    "# -----------------------------------------------------------------\n",
    "# Invoke 2\n",
    "result = conversational_qa_chain.invoke(\n",
    "    {\n",
    "        \"question\": \"Thanks. What about the conflict or disagreement resolution cases - roles of A, B, C. Can you enhance the answer please.\",\n",
    "        # \"chat_history\": [\n",
    "        #     HumanMessage(content=\"What is the best AI Agents framework?\"),\n",
    "        #     AIMessage(content=\"Autogen.\"),\n",
    "        # ],\n",
    "        \"chat_history\": chat_history,\n",
    "    },\n",
    "    config={\"callbacks\": [ConsoleCallbackHandler()]},\n",
    ")\n",
    "print(\"-------------------------Invoke 2-------------------------\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6bc470-5ebb-4a12-828f-f6ae0cbded9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_markdown(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8e2520-5d14-4327-a526-23436e643cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a09bbca-8e69-408f-8343-382c2ee75b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------\n",
    "chat_history.extend([HumanMessage(content=question), AIMessage(content=result.content)])\n",
    "# -----------------------------------------------------------------\n",
    "# Invoke 2\n",
    "result = conversational_qa_chain.invoke(\n",
    "    {\n",
    "        \"question\": \"Thanks. I need to really build the timeline - with all minimum/maximum terms or periods or deadlines mentioned in the text, and the stakeholders those timeframes relate to - broght together onto the timeline\",\n",
    "        # \"chat_history\": [\n",
    "        #     HumanMessage(content=\"What is the best AI Agents framework?\"),\n",
    "        #     AIMessage(content=\"Autogen.\"),\n",
    "        # ],\n",
    "        \"chat_history\": chat_history,\n",
    "    },\n",
    "    config={\"callbacks\": [ConsoleCallbackHandler()]},\n",
    ")\n",
    "print(\"-------------------------Invoke 2-------------------------\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafaba1d-b40e-43be-a803-cf4b5a51dada",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_markdown(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a29e7d0-63a3-462e-bd07-952f6ef00ef6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c422b080-0d1a-4d66-a09e-4cc809d2fe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------\n",
    "chat_history.extend([HumanMessage(content=question), AIMessage(content=result.content)])\n",
    "# -----------------------------------------------------------------\n",
    "# Invoke 2\n",
    "result = conversational_qa_chain.invoke(\n",
    "    {\n",
    "        \"question\": \"Thanks. Can you create one timeline for the steps, as you have just done - but adding citing of the relevant paragraphs of the text, mentioning the timelines\",\n",
    "        # \"chat_history\": [\n",
    "        #     HumanMessage(content=\"What is the best AI Agents framework?\"),\n",
    "        #     AIMessage(content=\"Autogen.\"),\n",
    "        # ],\n",
    "        \"chat_history\": chat_history,\n",
    "    },\n",
    "    config={\"callbacks\": [ConsoleCallbackHandler()]},\n",
    ")\n",
    "print(\"-------------------------Invoke 2-------------------------\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f1ca88-291c-4cdb-bd8a-bfd68351c8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_markdown(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcee758d-0639-4bd3-a952-63e3e5edaddb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
